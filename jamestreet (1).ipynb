{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"},{"sourceId":9910298,"sourceType":"datasetVersion","datasetId":6089181},{"sourceId":9918853,"sourceType":"datasetVersion","datasetId":6095754},{"sourceId":9985358,"sourceType":"datasetVersion","datasetId":6144936}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-12-12T23:08:26.706668Z","iopub.execute_input":"2024-12-12T23:08:26.707200Z","iopub.status.idle":"2024-12-12T23:08:27.163510Z","shell.execute_reply.started":"2024-12-12T23:08:26.707130Z","shell.execute_reply":"2024-12-12T23:08:27.162230Z"},"trusted":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"/kaggle/input/ai-env/requirements.txt\n/kaggle/input/requirments2/requirements2.txt\n/kaggle/input/jane-clean-priv/clean_data.parquet\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -r /kaggle/input/requirments2/requirements2.txt\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T19:53:10.262022Z","iopub.execute_input":"2025-01-03T19:53:10.262816Z","iopub.status.idle":"2025-01-03T19:53:19.478750Z","shell.execute_reply.started":"2025-01-03T19:53:10.262763Z","shell.execute_reply":"2025-01-03T19:53:19.477661Z"},"_kg_hide-input":true},"outputs":[{"name":"stdout","text":"Collecting absl-py==2.1.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 1))\n  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: asttokens==2.4.1 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 2)) (2.4.1)\nRequirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 3)) (1.6.3)\nRequirement already satisfied: certifi==2024.8.30 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 4)) (2024.8.30)\nCollecting charset-normalizer==3.4.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 5))\n  Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\nRequirement already satisfied: click==8.1.7 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 6)) (8.1.7)\nCollecting cloudpickle==3.1.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 7))\n  Downloading cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: colorama==0.4.6 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 8)) (0.4.6)\nRequirement already satisfied: comm==0.2.2 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 9)) (0.2.2)\nCollecting contourpy==1.3.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 10))\n  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\nRequirement already satisfied: cycler==0.12.1 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 11)) (0.12.1)\nCollecting dask==2024.11.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 12))\n  Downloading dask-2024.11.0-py3-none-any.whl.metadata (3.7 kB)\nCollecting dask-expr==1.1.17 (from -r /kaggle/input/requirments2/requirements2.txt (line 13))\n  Downloading dask_expr-1.1.17-py3-none-any.whl.metadata (2.6 kB)\nCollecting debugpy==1.8.7 (from -r /kaggle/input/requirments2/requirements2.txt (line 14))\n  Downloading debugpy-1.8.7-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: decorator==5.1.1 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 15)) (5.1.1)\nCollecting distributed==2024.11.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 16))\n  Downloading distributed-2024.11.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting executing==2.1.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 17))\n  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\nCollecting filelock==3.16.1 (from -r /kaggle/input/requirments2/requirements2.txt (line 18))\n  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: flatbuffers==24.3.25 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 19)) (24.3.25)\nCollecting fonttools==4.54.1 (from -r /kaggle/input/requirments2/requirements2.txt (line 20))\n  Downloading fonttools-4.54.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (163 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.7/163.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting fsspec==2024.10.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 21))\n  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: future==1.0.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 22)) (1.0.0)\nCollecting gast==0.6.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 23))\n  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: google-pasta==0.2.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 24)) (0.2.0)\nRequirement already satisfied: graphviz==0.20.3 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 25)) (0.20.3)\nCollecting grpcio==1.67.1 (from -r /kaggle/input/requirments2/requirements2.txt (line 26))\n  Downloading grpcio-1.67.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nCollecting h5py==3.12.1 (from -r /kaggle/input/requirments2/requirements2.txt (line 27))\n  Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting idna==3.10 (from -r /kaggle/input/requirments2/requirements2.txt (line 28))\n  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\nCollecting importlib_metadata==8.5.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 29))\n  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\nCollecting ipykernel==6.29.5 (from -r /kaggle/input/requirments2/requirements2.txt (line 30))\n  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\nCollecting ipython==8.29.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 31))\n  Downloading ipython-8.29.0-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: jedi==0.19.1 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 32)) (0.19.1)\nRequirement already satisfied: Jinja2==3.1.4 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 33)) (3.1.4)\nRequirement already satisfied: joblib==1.4.2 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 34)) (1.4.2)\nCollecting jupyter_client==8.6.3 (from -r /kaggle/input/requirments2/requirements2.txt (line 35))\n  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: jupyter_core==5.7.2 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 36)) (5.7.2)\nCollecting keras==3.6.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 37))\n  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\nCollecting kiwisolver==1.4.7 (from -r /kaggle/input/requirments2/requirements2.txt (line 38))\n  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\nRequirement already satisfied: libclang==18.1.1 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 39)) (18.1.1)\nRequirement already satisfied: locket==1.0.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 40)) (1.0.0)\nCollecting Markdown==3.7 (from -r /kaggle/input/requirments2/requirements2.txt (line 41))\n  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: markdown-it-py==3.0.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 42)) (3.0.0)\nCollecting MarkupSafe==3.0.2 (from -r /kaggle/input/requirments2/requirements2.txt (line 43))\n  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting matplotlib==3.9.2 (from -r /kaggle/input/requirments2/requirements2.txt (line 44))\n  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: matplotlib-inline==0.1.7 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 45)) (0.1.7)\nRequirement already satisfied: mdurl==0.1.2 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 46)) (0.1.2)\nCollecting ml-dtypes==0.4.1 (from -r /kaggle/input/requirments2/requirements2.txt (line 47))\n  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: mpmath==1.3.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 48)) (1.3.0)\nCollecting msgpack==1.1.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 49))\n  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\nRequirement already satisfied: namex==0.0.8 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 50)) (0.0.8)\nCollecting ncps==1.0.1 (from -r /kaggle/input/requirments2/requirements2.txt (line 51))\n  Downloading ncps-1.0.1-py3-none-any.whl.metadata (702 bytes)\nRequirement already satisfied: nest-asyncio==1.6.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 52)) (1.6.0)\nCollecting networkx==3.4.2 (from -r /kaggle/input/requirments2/requirements2.txt (line 53))\n  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\nCollecting numpy==2.1.3 (from -r /kaggle/input/requirments2/requirements2.txt (line 54))\n  Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opt_einsum==3.4.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 55))\n  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\nCollecting optree==0.13.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 56))\n  Downloading optree-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting packaging==24.1 (from -r /kaggle/input/requirments2/requirements2.txt (line 57))\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nCollecting pandas==2.2.3 (from -r /kaggle/input/requirments2/requirements2.txt (line 58))\n  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: parso==0.8.4 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 59)) (0.8.4)\nRequirement already satisfied: partd==1.4.2 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 60)) (1.4.2)\nCollecting pillow==11.0.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 61))\n  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\nCollecting platformdirs==4.3.6 (from -r /kaggle/input/requirments2/requirements2.txt (line 62))\n  Downloading platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\nCollecting polars==1.12.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 63))\n  Downloading polars-1.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\nCollecting prompt_toolkit==3.0.48 (from -r /kaggle/input/requirments2/requirements2.txt (line 64))\n  Downloading prompt_toolkit-3.0.48-py3-none-any.whl.metadata (6.4 kB)\nCollecting protobuf==5.28.3 (from -r /kaggle/input/requirments2/requirements2.txt (line 65))\n  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nCollecting psutil==6.1.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 66))\n  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\nCollecting pure_eval==0.2.3 (from -r /kaggle/input/requirments2/requirements2.txt (line 67))\n  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting pyarrow==18.0.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 68))\n  Downloading pyarrow-18.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\nCollecting pydot==3.0.2 (from -r /kaggle/input/requirments2/requirements2.txt (line 69))\n  Downloading pydot-3.0.2-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: Pygments==2.18.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 70)) (2.18.0)\nCollecting pyparsing==3.2.0 (from -r /kaggle/input/requirments2/requirements2.txt (line 71))\n  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: python-dateutil==2.9.0.post0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/input/requirments2/requirements2.txt (line 72)) (2.9.0.post0)\nCollecting pytz==2024.2 (from -r /kaggle/input/requirments2/requirements2.txt (line 73))\n  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==308 (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for pywin32==308\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import polars as pl\nlazy_frame=pl.scan_parquet(r\"/kaggle/input/jane-clean-priv\")\n\n#some preprocessing alread done reduced memory + skip first 500 dates and delete null columns\ny = lazy_frame.select('responder_6').collect()\nlazy_frame = lazy_frame.select([col for col in lazy_frame.columns if col != 'responder_6'])\nweights= lazy_frame.select(\"weight\")\n\nprint(\"done\")\n#df=pl.read_parquet(r\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T19:53:24.390991Z","iopub.execute_input":"2025-01-03T19:53:24.391617Z","iopub.status.idle":"2025-01-03T19:53:25.600988Z","shell.execute_reply.started":"2025-01-03T19:53:24.391582Z","shell.execute_reply":"2025-01-03T19:53:25.600127Z"}},"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/302229652.py:6: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n  lazy_frame = lazy_frame.select([col for col in lazy_frame.columns if col != 'responder_6'])\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install pmdarima\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T00:41:03.557842Z","iopub.execute_input":"2024-12-20T00:41:03.558815Z","iopub.status.idle":"2024-12-20T00:41:13.534366Z","shell.execute_reply.started":"2024-12-20T00:41:03.558765Z","shell.execute_reply":"2024-12-20T00:41:13.533475Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Collecting pmdarima\n  Downloading pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (1.4.2)\nRequirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (3.0.10)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (1.26.4)\nRequirement already satisfied: pandas>=0.19 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (2.2.2)\nRequirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (1.14.1)\nRequirement already satisfied: statsmodels>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (0.14.2)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (1.26.18)\nRequirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (70.0.0)\nRequirement already satisfied: packaging>=17.1 in /opt/conda/lib/python3.10/site-packages (from pmdarima) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.1->pmdarima) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.19->pmdarima) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.19->pmdarima) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.19->pmdarima) (2024.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->pmdarima) (3.5.0)\nRequirement already satisfied: patsy>=0.5.6 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13.2->pmdarima) (0.5.6)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.6->statsmodels>=0.13.2->pmdarima) (1.16.0)\nDownloading pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pmdarima\nSuccessfully installed pmdarima-2.0.4\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(y.shape)\ny.head() # y our target variable is all ready to go","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T01:26:50.837892Z","iopub.execute_input":"2024-12-19T01:26:50.838302Z","iopub.status.idle":"2024-12-19T01:26:50.847075Z","shell.execute_reply.started":"2024-12-19T01:26:50.838268Z","shell.execute_reply":"2024-12-19T01:26:50.845926Z"}},"outputs":[{"name":"stdout","text":"(39577181, 1)\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"shape: (5, 1)\n┌─────────────┐\n│ responder_6 │\n│ ---         │\n│ f32         │\n╞═════════════╡\n│ -0.310255   │\n│ 0.369653    │\n│ 0.776823    │\n│ 0.082477    │\n│ 0.66507     │\n└─────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>responder_6</th></tr><tr><td>f32</td></tr></thead><tbody><tr><td>-0.310255</td></tr><tr><td>0.369653</td></tr><tr><td>0.776823</td></tr><tr><td>0.082477</td></tr><tr><td>0.66507</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"print(df.estimated_size(\"gb\"))\n17.0601749420166\nprint(df.shape)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T01:22:48.155612Z","iopub.execute_input":"2024-12-16T01:22:48.156075Z","iopub.status.idle":"2024-12-16T01:22:48.171160Z","shell.execute_reply.started":"2024-12-16T01:22:48.156036Z","shell.execute_reply":"2024-12-16T01:22:48.169776Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"15.98888553865254\n(47127338, 93)\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"shape: (5, 93)\n┌─────────┬─────────┬───────────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n│ date_id ┆ time_id ┆ symbol_id ┆ weight   ┆ … ┆ responder_ ┆ responder_ ┆ responder_ ┆ partition_ │\n│ ---     ┆ ---     ┆ ---       ┆ ---      ┆   ┆ 6          ┆ 7          ┆ 8          ┆ id         │\n│ i16     ┆ i16     ┆ i8        ┆ f32      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n│         ┆         ┆           ┆          ┆   ┆ f32        ┆ f32        ┆ f32        ┆ i64        │\n╞═════════╪═════════╪═══════════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n│ 0       ┆ 0       ┆ 1         ┆ 3.889038 ┆ … ┆ 0.775981   ┆ 0.346999   ┆ 0.095504   ┆ 0          │\n│ 0       ┆ 0       ┆ 7         ┆ 1.370613 ┆ … ┆ 0.703665   ┆ 0.216683   ┆ 0.778639   ┆ 0          │\n│ 0       ┆ 0       ┆ 9         ┆ 2.285698 ┆ … ┆ 2.109352   ┆ 0.670881   ┆ 0.772828   ┆ 0          │\n│ 0       ┆ 0       ┆ 10        ┆ 0.690606 ┆ … ┆ 1.114137   ┆ 0.775199   ┆ -1.379516  ┆ 0          │\n│ 0       ┆ 0       ┆ 14        ┆ 0.44057  ┆ … ┆ -3.57282   ┆ -1.089123  ┆ -5.0       ┆ 0          │\n└─────────┴─────────┴───────────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 93)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>&hellip;</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_0</th><th>responder_1</th><th>responder_2</th><th>responder_3</th><th>responder_4</th><th>responder_5</th><th>responder_6</th><th>responder_7</th><th>responder_8</th><th>partition_id</th></tr><tr><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>1</td><td>3.889038</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.851033</td><td>0.242971</td><td>0.2634</td><td>-0.891687</td><td>11</td><td>7</td><td>76</td><td>-0.883028</td><td>0.003067</td><td>-0.744703</td><td>null</td><td>-0.169586</td><td>null</td><td>-1.335938</td><td>-1.707803</td><td>0.91013</td><td>null</td><td>1.636431</td><td>1.522133</td><td>-1.551398</td><td>-0.229627</td><td>null</td><td>null</td><td>1.378301</td><td>-0.283712</td><td>0.123196</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>-0.808103</td><td>null</td><td>-2.037683</td><td>0.727661</td><td>null</td><td>-0.989118</td><td>-0.345213</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.251104</td><td>-0.110252</td><td>-0.491157</td><td>-1.02269</td><td>0.152241</td><td>-0.659864</td><td>null</td><td>null</td><td>-0.261412</td><td>-0.211486</td><td>-0.335556</td><td>-0.281498</td><td>0.738489</td><td>-0.069556</td><td>1.380875</td><td>2.005353</td><td>0.186018</td><td>1.218368</td><td>0.775981</td><td>0.346999</td><td>0.095504</td><td>0</td></tr><tr><td>0</td><td>0</td><td>7</td><td>1.370613</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.676961</td><td>0.151984</td><td>0.192465</td><td>-0.521729</td><td>11</td><td>7</td><td>76</td><td>-0.865307</td><td>-0.225629</td><td>-0.582163</td><td>null</td><td>0.317467</td><td>null</td><td>-1.250016</td><td>-1.682929</td><td>1.412757</td><td>null</td><td>0.520378</td><td>0.744132</td><td>-0.788658</td><td>0.641776</td><td>null</td><td>null</td><td>0.2272</td><td>0.580907</td><td>1.128879</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>-1.625862</td><td>null</td><td>-1.410017</td><td>1.063013</td><td>null</td><td>0.888355</td><td>0.467994</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.065759</td><td>0.013322</td><td>-0.592855</td><td>-1.052685</td><td>-0.393726</td><td>-0.741603</td><td>null</td><td>null</td><td>-0.281207</td><td>-0.182894</td><td>-0.245565</td><td>-0.302441</td><td>2.965889</td><td>1.190077</td><td>-0.523998</td><td>3.849921</td><td>2.626981</td><td>5.0</td><td>0.703665</td><td>0.216683</td><td>0.778639</td><td>0</td></tr><tr><td>0</td><td>0</td><td>9</td><td>2.285698</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.056285</td><td>0.187227</td><td>0.249901</td><td>-0.77305</td><td>11</td><td>7</td><td>76</td><td>-0.675719</td><td>-0.199404</td><td>-0.586798</td><td>null</td><td>-0.814909</td><td>null</td><td>-1.296782</td><td>-2.040234</td><td>0.639589</td><td>null</td><td>1.597359</td><td>0.657514</td><td>-1.350148</td><td>0.364215</td><td>null</td><td>null</td><td>-0.017751</td><td>-0.317361</td><td>-0.122379</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>-0.72542</td><td>null</td><td>-2.29417</td><td>1.764551</td><td>null</td><td>-0.120789</td><td>-0.063458</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.882604</td><td>-0.072482</td><td>-0.617934</td><td>-0.86323</td><td>-0.241892</td><td>-0.709919</td><td>null</td><td>null</td><td>0.377131</td><td>0.300724</td><td>-0.106842</td><td>-0.096792</td><td>-0.864488</td><td>-0.280303</td><td>-0.326697</td><td>0.375781</td><td>1.271291</td><td>0.099793</td><td>2.109352</td><td>0.670881</td><td>0.772828</td><td>0</td></tr><tr><td>0</td><td>0</td><td>10</td><td>0.690606</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.139366</td><td>0.273328</td><td>0.306549</td><td>-1.262223</td><td>42</td><td>5</td><td>150</td><td>-0.694008</td><td>3.004091</td><td>0.114809</td><td>null</td><td>-0.251882</td><td>null</td><td>-1.902009</td><td>-0.979447</td><td>0.241165</td><td>null</td><td>-0.392359</td><td>-0.224699</td><td>-2.129397</td><td>-0.855287</td><td>null</td><td>null</td><td>0.404142</td><td>-0.578156</td><td>0.105702</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>1.313203</td><td>null</td><td>-0.810125</td><td>2.939022</td><td>null</td><td>3.988801</td><td>1.834661</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.697595</td><td>1.074309</td><td>-0.206929</td><td>-0.530602</td><td>4.765215</td><td>0.571554</td><td>null</td><td>null</td><td>-0.226891</td><td>-0.251412</td><td>-0.215522</td><td>-0.296244</td><td>0.408499</td><td>0.223992</td><td>2.294888</td><td>1.097444</td><td>1.225872</td><td>1.225376</td><td>1.114137</td><td>0.775199</td><td>-1.379516</td><td>0</td></tr><tr><td>0</td><td>0</td><td>14</td><td>0.44057</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.9552</td><td>0.262404</td><td>0.344457</td><td>-0.613813</td><td>44</td><td>3</td><td>16</td><td>-0.947351</td><td>-0.030018</td><td>-0.502379</td><td>null</td><td>0.646086</td><td>null</td><td>-1.844685</td><td>-1.58656</td><td>-0.182024</td><td>null</td><td>-0.969949</td><td>-0.673813</td><td>-1.282132</td><td>-1.399894</td><td>null</td><td>null</td><td>0.043815</td><td>-0.320225</td><td>-0.031713</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>0.476195</td><td>null</td><td>-0.771732</td><td>2.843421</td><td>null</td><td>1.379815</td><td>0.411827</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.948601</td><td>-0.136814</td><td>-0.447704</td><td>-1.141761</td><td>0.099631</td><td>-0.661928</td><td>null</td><td>null</td><td>3.678076</td><td>2.793581</td><td>2.61825</td><td>3.418133</td><td>-0.373387</td><td>-0.502764</td><td>-0.348021</td><td>-3.928148</td><td>-1.591366</td><td>-5.0</td><td>-3.57282</td><td>-1.089123</td><td>-5.0</td><td>0</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"Above code sorted out our target and dataset Below code is setting up a normal data set for GBM eventually im just going to get all the data preprocessing done all in one file and upload it so code below right now is not that important as training will be done on a lean data set for now","metadata":{}},{"cell_type":"code","source":"from polars import col\nimport numpy as np\nresps = df.select([col(f'responder_{i}') for i in range(1, 5)])\nresps.head()\nlen_col=resps.height\nprint(len_col)\nresps.head()\nassert not np.any(np.isnan(resps)) and not np.any(np.isinf(resps)), \"resps contains NaN or infinite values!\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T23:10:03.972564Z","iopub.execute_input":"2024-12-20T23:10:03.972917Z","iopub.status.idle":"2024-12-20T23:10:04.000057Z","shell.execute_reply.started":"2024-12-20T23:10:03.972885Z","shell.execute_reply":"2024-12-20T23:10:03.998711Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolars\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m col\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m resps \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mselect([col(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponder_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m)])\n\u001b[1;32m      4\u001b[0m resps\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m      5\u001b[0m len_col\u001b[38;5;241m=\u001b[39mresps\u001b[38;5;241m.\u001b[39mheight\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"],"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"import torch \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Print the device being used\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T19:06:05.812863Z","iopub.execute_input":"2024-12-14T19:06:05.813177Z","iopub.status.idle":"2024-12-14T19:06:08.813097Z","shell.execute_reply.started":"2024-12-14T19:06:05.813149Z","shell.execute_reply":"2024-12-14T19:06:08.812176Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"torch.cuda.empty_cache()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T19:06:08.814081Z","iopub.execute_input":"2024-12-14T19:06:08.814406Z","iopub.status.idle":"2024-12-14T19:06:08.818684Z","shell.execute_reply.started":"2024-12-14T19:06:08.814382Z","shell.execute_reply":"2024-12-14T19:06:08.817888Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Brownian motion will talk about more and add image","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom tqdm import tqdm\n\n# Ensure that 'resps' is valid (no NaN or infinite values)\nassert not np.any(np.isnan(resps)) and not np.any(np.isinf(resps)), \"resps contains NaN or infinite values!\"\n\ndef train_gbm(batch_size):\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Initialize dT, sigma, and mu\n    dT_init = np.ones(4-1).astype(float)\n    sigma_init = np.random.randn(batch_size) * 0.01 + 1\n    mu_param = torch.tensor(np.random.randn(batch_size) * 0.01, device=device).requires_grad_(True)\n    \n    with torch.no_grad():\n        dT_param_log = torch.log(torch.tensor(dT_init + 1e-6)).to(device).requires_grad_(True)\n        sigma_param_log = torch.log(torch.tensor(sigma_init + 1e-6)).to(device).requires_grad_(True)\n    \n    W = torch.tensor(resps.to_numpy() + 1, device=device).float()\n    W = torch.clamp(W, min=1e-6)  # Ensure no zero or negative values\n\n    W_init = torch.cat((torch.ones((W.size(0), 1)).to(device), W[:, :-1]), dim=1)\n    W_init = torch.clamp(W_init, min=1e-6)  # Ensure no zero or negative values\n\n    if torch.any(W <= 0) or torch.any(W_init <= 0):\n        print(f\"Warning: Found non-positive values in W or W_init: min(W)={W.min()}, min(W_init)={W_init.min()}\")\n    \n    # Optimizer setup\n    opt = torch.optim.Adam([dT_param_log, sigma_param_log, mu_param], lr=0.001)\n\n    # Calculate the number of batches\n    num_batches = len(resps) // batch_size\n\n    for iteration in tqdm(range(4000)):\n        opt.zero_grad()\n\n        # Loop over mini-batches\n        for batch_idx in range(num_batches):\n            # Get the current batch data\n            batch_start = batch_idx * batch_size\n            batch_end = min((batch_idx + 1) * batch_size, len(resps))\n            W_batch = W[batch_start:batch_end]\n            W_init_batch = W_init[batch_start:batch_end]\n\n            # Add the fixed 1 at the beginning of the time deltas\n            dT_log = torch.cat([torch.zeros(1, device=device), dT_param_log])\n            dT = torch.exp(dT_log).view((1, -1))\n            sigmas = torch.exp(sigma_param_log).view((-1, 1))\n            mus = mu_param.view((-1, 1))\n\n            ln_W = torch.log(W_batch)\n            ln_W_init = torch.log(W_init_batch)\n            \n            # Compute log probability\n            log_prob = -ln_W - torch.log(sigmas) - 0.5 * torch.log(dT) - (ln_W - ln_W_init - (mus - 0.5 * sigmas**2) @ dT)**2 / (2 * sigmas**2 @ dT)\n            \n            row_likelihood = log_prob.sum(dim=1)\n            total_likelihood = row_likelihood.mean(dim=0)\n            \n            negative_total_likelihood = -total_likelihood\n            \n            # Debugging step: Check if NaN values appear in the calculation\n            if torch.isnan(negative_total_likelihood).any():\n                print(f\"NaN detected in negative_total_likelihood at iteration {iteration}\")\n            \n            #if iteration % 1000 == 0:\n                #print(f\"Iteration {iteration}, Negative Total Likelihood: {negative_total_likelihood.item()}\")\n            if batch_idx == num_batches - 1  and iteration % 100 == 0: # Last mini-batch\n                print(f\"Iteration {iteration}, Negative Total Likelihood (last mini-batch): {negative_total_likelihood.item()}\")\n            \n            negative_total_likelihood.backward()\n\n        opt.step()\n\n        # Debugging: Check for NaNs in updated parameters\n        if torch.isnan(mu_param).any() or torch.isnan(sigma_param_log).any() or torch.isnan(dT_param_log).any():\n            print(f\"NaN detected in parameters at iteration {iteration}\")\n            break\n    \n    # After training, detach and return results\n    mus = mu_param.detach().cpu().numpy()\n    sigmas = torch.exp(sigma_param_log).detach().cpu().numpy()\n    \n    return mus, sigmas\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T19:06:08.820095Z","iopub.execute_input":"2024-12-14T19:06:08.820422Z","iopub.status.idle":"2024-12-14T19:06:09.549371Z","shell.execute_reply.started":"2024-12-14T19:06:08.820386Z","shell.execute_reply":"2024-12-14T19:06:09.548679Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import polars as pl\nimport os\nfrom tqdm import tqdm\n\ndef train_gbm_full(df, batch_size):\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    all_mus, all_sigmas = [], []\n\n    for batch_start in range(0, len(df), batch_size):\n        batch_end = min(batch_start + batch_size, len(df))\n        resps_batch = resps[batch_start:batch_end]\n        \n        # Ensure batch data validity\n        assert not np.any(np.isnan(resps_batch)) and not np.any(np.isinf(resps_batch)), \"Batch contains NaN or infinite values!\"\n        \n        # Call `train_gbm` with the current batch\n        mus, sigmas = train_gbm(batch_size=len(resps_batch))\n        all_mus.append(mus)\n        all_sigmas.append(sigmas)\n        results_df = pl.DataFrame({\n        'mus': mus.flatten(),  # Flatten to ensure it's a 1D array\n        'sigmas': sigmas.flatten(),\n        })\n        path=r\"D:\\jane-street-real-time-market-data-forecasting\"\n        file_name = f\"gbm_augmented_training_data_batch_safe_{batch_start}.parquet\"\n        df.write_parquet(file_name)\n        !ls /kaggle/working\n\n    # Flatten and concatenate all results\n    all_mus = np.concatenate(all_mus, axis=0)\n    all_sigmas = np.concatenate(all_sigmas, axis=0)\n    \n    return all_mus, all_sigmas\n\n# Call the modified function\nmus, sigmas = train_gbm_full(resps, batch_size=13000000)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T19:06:15.086838Z","iopub.execute_input":"2024-12-14T19:06:15.087161Z","iopub.status.idle":"2024-12-14T20:30:48.280506Z","shell.execute_reply.started":"2024-12-14T19:06:15.087137Z","shell.execute_reply":"2024-12-14T20:30:48.279230Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 1/4000 [00:00<47:08,  1.41it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Negative Total Likelihood (last mini-batch): 15.192374951040884\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 101/4000 [00:31<19:59,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Negative Total Likelihood (last mini-batch): 10.977711066048462\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 201/4000 [01:02<19:29,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 200, Negative Total Likelihood (last mini-batch): 8.196219737650138\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 301/4000 [01:33<18:59,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 300, Negative Total Likelihood (last mini-batch): 6.3022903858241\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 401/4000 [02:03<18:28,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 400, Negative Total Likelihood (last mini-batch): 4.966340131842988\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 501/4000 [02:34<18:00,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 500, Negative Total Likelihood (last mini-batch): 3.9804421217267216\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 601/4000 [03:05<17:28,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 600, Negative Total Likelihood (last mini-batch): 3.2213892810057336\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 701/4000 [03:36<16:58,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 700, Negative Total Likelihood (last mini-batch): 2.6203585396319102\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 801/4000 [04:07<16:27,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 800, Negative Total Likelihood (last mini-batch): 2.1358906595185476\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 901/4000 [04:38<15:55,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 900, Negative Total Likelihood (last mini-batch): 1.7403106568373476\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 1001/4000 [05:08<15:25,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1000, Negative Total Likelihood (last mini-batch): 1.4140946089008937\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 1101/4000 [05:39<14:55,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1100, Negative Total Likelihood (last mini-batch): 1.1429867167635996\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 1201/4000 [06:10<14:23,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1200, Negative Total Likelihood (last mini-batch): 0.9162726207804682\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 1301/4000 [06:41<13:53,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1300, Negative Total Likelihood (last mini-batch): 0.7256953807016477\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 1401/4000 [07:12<13:21,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1400, Negative Total Likelihood (last mini-batch): 0.5647534641343299\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 1501/4000 [07:43<12:51,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1500, Negative Total Likelihood (last mini-batch): 0.42823430537505547\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 1601/4000 [08:13<12:20,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1600, Negative Total Likelihood (last mini-batch): 0.31189850305373795\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 1701/4000 [08:44<11:50,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1700, Negative Total Likelihood (last mini-batch): 0.2122626553707299\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 1801/4000 [09:15<11:18,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1800, Negative Total Likelihood (last mini-batch): 0.12644734618783834\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 1901/4000 [09:46<10:48,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1900, Negative Total Likelihood (last mini-batch): 0.05206795745866191\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 2001/4000 [10:17<10:16,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2000, Negative Total Likelihood (last mini-batch): -0.01284679700304253\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 2101/4000 [10:48<09:46,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2100, Negative Total Likelihood (last mini-batch): -0.06991875299974096\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 2201/4000 [11:19<09:15,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2200, Negative Total Likelihood (last mini-batch): -0.1204731570370311\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 2301/4000 [11:49<08:44,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2300, Negative Total Likelihood (last mini-batch): -0.1655844636949174\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 2401/4000 [12:20<08:13,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2400, Negative Total Likelihood (last mini-batch): -0.2061171649189965\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 2501/4000 [12:51<07:42,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2500, Negative Total Likelihood (last mini-batch): -0.24276251029125281\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 2601/4000 [13:22<07:11,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2600, Negative Total Likelihood (last mini-batch): -0.27607126836071766\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 2701/4000 [13:53<06:40,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2700, Negative Total Likelihood (last mini-batch): -0.3064823899274926\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 2801/4000 [14:24<06:09,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2800, Negative Total Likelihood (last mini-batch): -0.3343474381972469\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 2901/4000 [14:54<05:39,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2900, Negative Total Likelihood (last mini-batch): -0.35995081555554687\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 3001/4000 [15:25<05:08,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3000, Negative Total Likelihood (last mini-batch): -0.3835260263974493\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 3101/4000 [15:56<04:37,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3100, Negative Total Likelihood (last mini-batch): -0.40526838952553546\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 3201/4000 [16:27<04:06,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3200, Negative Total Likelihood (last mini-batch): -0.42534471420601416\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 3301/4000 [16:58<03:35,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3300, Negative Total Likelihood (last mini-batch): -0.44390047926987497\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 3401/4000 [17:29<03:04,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3400, Negative Total Likelihood (last mini-batch): -0.46106502411132566\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 3501/4000 [18:00<02:34,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3500, Negative Total Likelihood (last mini-batch): -0.47695519918828144\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 3601/4000 [18:30<02:03,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3600, Negative Total Likelihood (last mini-batch): -0.4916778520281666\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 3701/4000 [19:01<01:32,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3700, Negative Total Likelihood (last mini-batch): -0.5053314558724191\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 3801/4000 [19:32<01:01,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3800, Negative Total Likelihood (last mini-batch): -0.5180071235967038\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 3901/4000 [20:03<00:30,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3900, Negative Total Likelihood (last mini-batch): -0.5297892095520751\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4000/4000 [20:33<00:00,  3.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"gbm_augmented_training_data_batch_safe_0.parquet\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/4000 [00:00<20:41,  3.22it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Negative Total Likelihood (last mini-batch): 15.192233680215868\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 101/4000 [00:31<19:59,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Negative Total Likelihood (last mini-batch): 10.97761036354485\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 201/4000 [01:01<19:32,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 200, Negative Total Likelihood (last mini-batch): 8.196141414169382\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 301/4000 [01:32<19:00,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 300, Negative Total Likelihood (last mini-batch): 6.302226579162086\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 401/4000 [02:03<18:30,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 400, Negative Total Likelihood (last mini-batch): 4.966287105634986\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 501/4000 [02:34<17:58,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 500, Negative Total Likelihood (last mini-batch): 3.980397670814415\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 601/4000 [03:05<17:29,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 600, Negative Total Likelihood (last mini-batch): 3.221351757961171\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 701/4000 [03:36<16:56,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 700, Negative Total Likelihood (last mini-batch): 2.6203265853860223\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 801/4000 [04:06<16:27,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 800, Negative Total Likelihood (last mini-batch): 2.1358632823242956\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 901/4000 [04:37<15:55,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 900, Negative Total Likelihood (last mini-batch): 1.7402871895762593\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 1001/4000 [05:08<15:25,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1000, Negative Total Likelihood (last mini-batch): 1.4140745824455527\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 1101/4000 [05:39<14:53,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1100, Negative Total Likelihood (last mini-batch): 1.1429697657059104\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 1201/4000 [06:10<14:23,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1200, Negative Total Likelihood (last mini-batch): 0.9162584297914622\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 1301/4000 [06:41<13:52,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1300, Negative Total Likelihood (last mini-batch): 0.7256836532220866\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 1401/4000 [07:12<13:21,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1400, Negative Total Likelihood (last mini-batch): 0.5647439139844486\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 1501/4000 [07:42<12:50,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1500, Negative Total Likelihood (last mini-batch): 0.42822666675439613\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 1601/4000 [08:13<12:19,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1600, Negative Total Likelihood (last mini-batch): 0.3118925479608112\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 1701/4000 [08:44<11:49,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1700, Negative Total Likelihood (last mini-batch): 0.21225820750689536\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 1801/4000 [09:15<11:18,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1800, Negative Total Likelihood (last mini-batch): 0.12644428449679262\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 1901/4000 [09:46<10:47,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1900, Negative Total Likelihood (last mini-batch): 0.052066208061458265\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 2001/4000 [10:17<10:16,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2000, Negative Total Likelihood (last mini-batch): -0.012847277076941959\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 2101/4000 [10:47<09:46,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2100, Negative Total Likelihood (last mini-batch): -0.06991799478985412\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 2201/4000 [11:18<09:14,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2200, Negative Total Likelihood (last mini-batch): -0.12047119631574321\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 2301/4000 [11:49<08:44,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2300, Negative Total Likelihood (last mini-batch): -0.16558135224622347\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 2401/4000 [12:20<08:12,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2400, Negative Total Likelihood (last mini-batch): -0.20611297553688265\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 2501/4000 [12:51<07:42,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2500, Negative Total Likelihood (last mini-batch): -0.24275733623786028\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 2601/4000 [13:22<07:11,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2600, Negative Total Likelihood (last mini-batch): -0.2760652189105494\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 2701/4000 [13:52<06:41,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2700, Negative Total Likelihood (last mini-batch): -0.3064755838721616\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 2801/4000 [14:23<06:09,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2800, Negative Total Likelihood (last mini-batch): -0.33433999699258055\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 2901/4000 [14:54<05:39,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2900, Negative Total Likelihood (last mini-batch): -0.35994285734302056\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 3001/4000 [15:25<05:08,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3000, Negative Total Likelihood (last mini-batch): -0.3835176615851212\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 3101/4000 [15:56<04:37,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3100, Negative Total Likelihood (last mini-batch): -0.40525971810478933\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 3201/4000 [16:27<04:06,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3200, Negative Total Likelihood (last mini-batch): -0.4253358246030619\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 3301/4000 [16:58<03:35,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3300, Negative Total Likelihood (last mini-batch): -0.44389144832405303\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 3401/4000 [17:28<03:04,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3400, Negative Total Likelihood (last mini-batch): -0.4610559177246428\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 3501/4000 [17:59<02:33,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3500, Negative Total Likelihood (last mini-batch): -0.47694607325937755\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 3601/4000 [18:30<02:03,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3600, Negative Total Likelihood (last mini-batch): -0.4916687534591485\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 3701/4000 [19:01<01:31,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3700, Negative Total Likelihood (last mini-batch): -0.5053224235843201\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 3801/4000 [19:32<01:01,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3800, Negative Total Likelihood (last mini-batch): -0.517998189526629\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 3901/4000 [20:02<00:30,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3900, Negative Total Likelihood (last mini-batch): -0.5297803937122032\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4000/4000 [20:33<00:00,  3.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"gbm_augmented_training_data_batch_safe_0.parquet\ngbm_augmented_training_data_batch_safe_13000000.parquet\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/4000 [00:00<20:38,  3.23it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Negative Total Likelihood (last mini-batch): 15.192545457473814\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 101/4000 [00:31<20:00,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Negative Total Likelihood (last mini-batch): 10.977845492469333\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 201/4000 [01:01<19:31,  3.24it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 200, Negative Total Likelihood (last mini-batch): 8.196327644301109\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 301/4000 [01:32<18:58,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 300, Negative Total Likelihood (last mini-batch): 6.302379276757016\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 401/4000 [02:03<18:28,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 400, Negative Total Likelihood (last mini-batch): 4.966413485668624\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 501/4000 [02:34<17:57,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 500, Negative Total Likelihood (last mini-batch): 3.9805033320510836\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 601/4000 [03:05<17:26,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 600, Negative Total Likelihood (last mini-batch): 3.2214416670834147\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 701/4000 [03:35<16:55,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 700, Negative Total Likelihood (last mini-batch): 2.6204045012625237\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 801/4000 [04:06<16:23,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 800, Negative Total Likelihood (last mini-batch): 2.1359318099522584\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 901/4000 [04:37<15:54,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 900, Negative Total Likelihood (last mini-batch): 1.7403480826348192\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 1001/4000 [05:08<15:22,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1000, Negative Total Likelihood (last mini-batch): 1.4141290047803332\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 1101/4000 [05:38<14:51,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1100, Negative Total Likelihood (last mini-batch): 1.1430184994727024\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 1201/4000 [06:09<14:20,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1200, Negative Total Likelihood (last mini-batch): 0.916302034626812\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 1301/4000 [06:40<13:49,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1300, Negative Total Likelihood (last mini-batch): 0.7257225806788145\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 1401/4000 [07:11<13:19,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1400, Negative Total Likelihood (last mini-batch): 0.5647785752734407\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 1501/4000 [07:41<12:48,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1500, Negative Total Likelihood (last mini-batch): 0.4282574590673107\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 1601/4000 [08:12<12:17,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1600, Negative Total Likelihood (last mini-batch): 0.31191985301230535\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 1701/4000 [08:43<11:47,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1700, Negative Total Likelihood (last mini-batch): 0.212282378719194\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 1801/4000 [09:14<11:17,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1800, Negative Total Likelihood (last mini-batch): 0.1264656365510066\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 1901/4000 [09:45<10:45,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1900, Negative Total Likelihood (last mini-batch): 0.052085015949548716\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 2001/4000 [10:15<10:15,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2000, Negative Total Likelihood (last mini-batch): -0.012830769695192723\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 2101/4000 [10:46<09:44,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2100, Negative Total Likelihood (last mini-batch): -0.06990356299733298\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 2201/4000 [11:17<09:13,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2200, Negative Total Likelihood (last mini-batch): -0.12045862314512781\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 2301/4000 [11:48<08:42,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2300, Negative Total Likelihood (last mini-batch): -0.16557042350201198\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 2401/4000 [12:18<08:12,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2400, Negative Total Likelihood (last mini-batch): -0.20610348072473786\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 2501/4000 [12:49<07:41,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2500, Negative Total Likelihood (last mini-batch): -0.24274907357819006\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 2601/4000 [13:20<07:10,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2600, Negative Total Likelihood (last mini-batch): -0.27605800156285365\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 2701/4000 [13:51<06:39,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2700, Negative Total Likelihood (last mini-batch): -0.3064692450498415\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 2801/4000 [14:21<06:08,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2800, Negative Total Likelihood (last mini-batch): -0.334334392804082\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 2901/4000 [14:52<05:37,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2900, Negative Total Likelihood (last mini-batch): -0.3599378672418412\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 3001/4000 [15:23<05:07,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3000, Negative Total Likelihood (last mini-batch): -0.38351318692392566\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 3101/4000 [15:54<04:36,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3100, Negative Total Likelihood (last mini-batch): -0.405255679488297\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 3201/4000 [16:25<04:06,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3200, Negative Total Likelihood (last mini-batch): -0.4253321586901457\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 3301/4000 [16:55<03:35,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3300, Negative Total Likelihood (last mini-batch): -0.44388810459522215\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 3401/4000 [17:26<03:04,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3400, Negative Total Likelihood (last mini-batch): -0.4610528555833739\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 3501/4000 [17:57<02:33,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3500, Negative Total Likelihood (last mini-batch): -0.47694325969264884\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 3601/4000 [18:28<02:02,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3600, Negative Total Likelihood (last mini-batch): -0.4916661615284224\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 3701/4000 [18:58<01:32,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3700, Negative Total Likelihood (last mini-batch): -0.5053200301419507\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 3801/4000 [19:29<01:01,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3800, Negative Total Likelihood (last mini-batch): -0.5179959773947944\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 3901/4000 [20:00<00:30,  3.25it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3900, Negative Total Likelihood (last mini-batch): -0.5297783469823609\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4000/4000 [20:30<00:00,  3.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"gbm_augmented_training_data_batch_safe_0.parquet\ngbm_augmented_training_data_batch_safe_13000000.parquet\ngbm_augmented_training_data_batch_safe_26000000.parquet\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/4000 [00:00<23:17,  2.86it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Negative Total Likelihood (last mini-batch): 8.894097236006488\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 101/4000 [00:34<22:04,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Negative Total Likelihood (last mini-batch): 7.066846255213192\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 201/4000 [01:07<21:20,  2.97it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 200, Negative Total Likelihood (last mini-batch): 5.959860214498984\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 301/4000 [01:41<20:44,  2.97it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 300, Negative Total Likelihood (last mini-batch): 5.268066068184963\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 401/4000 [02:15<20:18,  2.95it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 400, Negative Total Likelihood (last mini-batch): 4.8233507987005195\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 501/4000 [02:49<19:49,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 500, Negative Total Likelihood (last mini-batch): 4.530904899876068\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 601/4000 [03:23<19:14,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 600, Negative Total Likelihood (last mini-batch): 4.334771108743373\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 701/4000 [03:57<18:31,  2.97it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 700, Negative Total Likelihood (last mini-batch): 4.2008278004834505\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 801/4000 [04:31<18:02,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 800, Negative Total Likelihood (last mini-batch): 4.107798135162672\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 901/4000 [05:05<17:25,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 900, Negative Total Likelihood (last mini-batch): 4.042217284819636\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 1001/4000 [05:39<17:02,  2.93it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1000, Negative Total Likelihood (last mini-batch): 3.9954759806978637\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 1101/4000 [06:12<16:25,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1100, Negative Total Likelihood (last mini-batch): 3.962018080187227\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 1201/4000 [06:46<15:46,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1200, Negative Total Likelihood (last mini-batch): 3.938213390081018\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 1301/4000 [07:20<15:17,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1300, Negative Total Likelihood (last mini-batch): 3.921642954194365\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 1401/4000 [07:54<14:43,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1400, Negative Total Likelihood (last mini-batch): 3.9106447282128327\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 1501/4000 [08:28<14:03,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1500, Negative Total Likelihood (last mini-batch): 3.904027122956057\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 1601/4000 [09:02<13:31,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1600, Negative Total Likelihood (last mini-batch): 3.9008916135402516\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 1701/4000 [09:36<12:55,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1700, Negative Total Likelihood (last mini-batch): 3.9005258293366016\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 1801/4000 [10:10<12:23,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1800, Negative Total Likelihood (last mini-batch): 3.902341368762155\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 1901/4000 [10:43<11:50,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 1900, Negative Total Likelihood (last mini-batch): 3.905839103036354\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 2001/4000 [11:17<11:17,  2.95it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2000, Negative Total Likelihood (last mini-batch): 3.9105905673890264\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 2101/4000 [11:51<10:44,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2100, Negative Total Likelihood (last mini-batch): 3.9162280968797285\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 2201/4000 [12:25<10:10,  2.95it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2200, Negative Total Likelihood (last mini-batch): 3.9224391868216317\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 2301/4000 [12:59<09:33,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2300, Negative Total Likelihood (last mini-batch): 3.928962484703676\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 2401/4000 [13:33<09:01,  2.95it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2400, Negative Total Likelihood (last mini-batch): 3.93558408473301\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 2501/4000 [14:07<08:31,  2.93it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2500, Negative Total Likelihood (last mini-batch): 3.9421335745106303\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 2601/4000 [14:40<07:53,  2.95it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2600, Negative Total Likelihood (last mini-batch): 3.948479718832566\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 2701/4000 [15:14<07:18,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2700, Negative Total Likelihood (last mini-batch): 3.9545258740463543\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 2801/4000 [15:48<06:47,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2800, Negative Total Likelihood (last mini-batch): 3.9602052975624584\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 2901/4000 [16:22<06:12,  2.95it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 2900, Negative Total Likelihood (last mini-batch): 3.9654765156370955\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 3001/4000 [16:56<05:39,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3000, Negative Total Likelihood (last mini-batch): 3.9703188807531986\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 3101/4000 [17:30<05:02,  2.97it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3100, Negative Total Likelihood (last mini-batch): 3.9747284123596027\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 3201/4000 [18:04<04:29,  2.97it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3200, Negative Total Likelihood (last mini-batch): 3.9787139830258687\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 3301/4000 [18:37<03:55,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3300, Negative Total Likelihood (last mini-batch): 3.982293889549333\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 3401/4000 [19:11<03:23,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3400, Negative Total Likelihood (last mini-batch): 3.985492833952288\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 3501/4000 [19:45<02:48,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3500, Negative Total Likelihood (last mini-batch): 3.988339329544581\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 3601/4000 [20:19<02:15,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3600, Negative Total Likelihood (last mini-batch): 3.990863539174404\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 3701/4000 [20:53<01:41,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3700, Negative Total Likelihood (last mini-batch): 3.99309554410764\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 3801/4000 [21:27<01:07,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3800, Negative Total Likelihood (last mini-batch): 3.995064032071649\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 3901/4000 [22:01<00:33,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 3900, Negative Total Likelihood (last mini-batch): 3.9967953811703367\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4000/4000 [22:34<00:00,  2.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"gbm_augmented_training_data_batch_safe_0.parquet\ngbm_augmented_training_data_batch_safe_13000000.parquet\ngbm_augmented_training_data_batch_safe_26000000.parquet\ngbm_augmented_training_data_batch_safe_39000000.parquet\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Ensure the final arrays match the length of the original DataFrame\nassert len(mus) == len(df), \"Mismatch in mus length!\"\nassert len(sigmas) == len(df), \"Mismatch in sigmas length!\"\n\n# Add results to the original DataFrame\nresults_df = pl.DataFrame({\n    'mus': mus.flatten(),  # Flatten to ensure it's a 1D array\n    'sigmas': sigmas.flatten(),\n})\n\nassert len(df) == len(results_df), \"Row count mismatch between original_df and results_df!\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T20:46:32.525080Z","iopub.execute_input":"2024-12-14T20:46:32.525784Z","iopub.status.idle":"2024-12-14T20:46:32.745984Z","shell.execute_reply.started":"2024-12-14T20:46:32.525747Z","shell.execute_reply":"2024-12-14T20:46:32.745267Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"\ndf= df.with_columns([\n    results_df['mus'],  # Add mus from results_df\n    results_df['sigmas']  # Add sigmas from results_df\n])\ndf.write_parquet(\"data_with_GBM_true\")\n!ls /kaggle/working\n\n# Alternatively, you can insert them at specific positions if you need to\n# final_df = original_df.insert_at_idx(idx, results_df['mus'])\n\n# Print the concatenated DataFrame\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T20:46:44.582706Z","iopub.execute_input":"2024-12-14T20:46:44.583036Z","iopub.status.idle":"2024-12-14T20:47:17.152385Z","shell.execute_reply.started":"2024-12-14T20:46:44.583008Z","shell.execute_reply":"2024-12-14T20:47:17.151343Z"}},"outputs":[{"name":"stdout","text":"data_with_GBM\ngbm_augmented_training_data_batch_safe_0.parquet\ngbm_augmented_training_data_batch_safe_13000000.parquet\ngbm_augmented_training_data_batch_safe_26000000.parquet\ngbm_augmented_training_data_batch_safe_39000000.parquet\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"shape: (5, 55)\n┌───────┬─────────┬─────────┬───────────┬───┬─────────────┬──────────────┬──────────┬──────────┐\n│ index ┆ date_id ┆ time_id ┆ symbol_id ┆ … ┆ responder_8 ┆ partition_id ┆ mus      ┆ sigmas   │\n│ ---   ┆ ---     ┆ ---     ┆ ---       ┆   ┆ ---         ┆ ---          ┆ ---      ┆ ---      │\n│ u32   ┆ i16     ┆ i16     ┆ i8        ┆   ┆ f32         ┆ i8           ┆ f64      ┆ f64      │\n╞═══════╪═════════╪═════════╪═══════════╪═══╪═════════════╪══════════════╪══════════╪══════════╡\n│ 0     ┆ 500     ┆ 0       ┆ 1         ┆ … ┆ 0.286226    ┆ 2            ┆ 0.197659 ┆ 0.677686 │\n│ 1     ┆ 500     ┆ 0       ┆ 2         ┆ … ┆ 0.424229    ┆ 2            ┆ 0.039092 ┆ 0.17127  │\n│ 2     ┆ 500     ┆ 0       ┆ 3         ┆ … ┆ -0.480423   ┆ 2            ┆ 0.022386 ┆ 0.202336 │\n│ 3     ┆ 500     ┆ 0       ┆ 5         ┆ … ┆ -0.93745    ┆ 2            ┆ 2.814211 ┆ 2.403637 │\n│ 4     ┆ 500     ┆ 0       ┆ 7         ┆ … ┆ 1.543351    ┆ 2            ┆ 3.596194 ┆ 2.891145 │\n└───────┴─────────┴─────────┴───────────┴───┴─────────────┴──────────────┴──────────┴──────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 55)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_20</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_34</th><th>feature_35</th><th>feature_36</th><th>feature_38</th><th>feature_47</th><th>feature_48</th><th>feature_49</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>responder_0</th><th>responder_1</th><th>responder_2</th><th>responder_3</th><th>responder_4</th><th>responder_5</th><th>responder_6</th><th>responder_7</th><th>responder_8</th><th>partition_id</th><th>mus</th><th>sigmas</th></tr><tr><td>u32</td><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>500</td><td>0</td><td>1</td><td>4.372602</td><td>0.963079</td><td>0.84618</td><td>1.939234</td><td>1.16474</td><td>-3.205123</td><td>1.400332</td><td>1.898511</td><td>0.741687</td><td>11</td><td>7</td><td>76</td><td>-0.868997</td><td>0.425592</td><td>-0.567527</td><td>1.045398</td><td>2.7043</td><td>1.706279</td><td>0.158466</td><td>0.663829</td><td>1.811922</td><td>-0.342157</td><td>-0.454954</td><td>1.539099</td><td>1.550841</td><td>2.522677</td><td>-0.960886</td><td>1.230461</td><td>1.48645</td><td>1.36182</td><td>1.671203</td><td>0.640596</td><td>0.202007</td><td>-0.839841</td><td>0.338598</td><td>-0.424715</td><td>-1.003515</td><td>0.59359</td><td>-0.449099</td><td>-0.788824</td><td>-0.48744</td><td>-0.964526</td><td>-0.626286</td><td>-0.334997</td><td>-0.268242</td><td>-0.310255</td><td>-0.004007</td><td>0.286226</td><td>2</td><td>0.197659</td><td>0.677686</td></tr><tr><td>1</td><td>500</td><td>0</td><td>2</td><td>1.199431</td><td>0.999282</td><td>0.764294</td><td>1.495962</td><td>1.022274</td><td>-3.490678</td><td>2.477362</td><td>1.646399</td><td>0.750717</td><td>81</td><td>2</td><td>59</td><td>-1.189323</td><td>-0.369424</td><td>-0.490278</td><td>-0.578691</td><td>-0.466578</td><td>-0.832514</td><td>0.216229</td><td>-0.178512</td><td>0.522295</td><td>-0.337715</td><td>-0.75995</td><td>1.110195</td><td>-0.060456</td><td>-1.593359</td><td>-0.357835</td><td>-0.480974</td><td>-1.441863</td><td>-0.797337</td><td>-0.942976</td><td>-0.517649</td><td>0.202007</td><td>-1.052028</td><td>-0.368874</td><td>-0.689406</td><td>-0.665303</td><td>-0.233074</td><td>-0.753893</td><td>-0.291857</td><td>-0.329453</td><td>0.17402</td><td>0.122967</td><td>0.603747</td><td>0.371612</td><td>0.369653</td><td>0.823404</td><td>0.424229</td><td>2</td><td>0.039092</td><td>0.17127</td></tr><tr><td>2</td><td>500</td><td>0</td><td>3</td><td>0.689271</td><td>2.156528</td><td>0.379673</td><td>1.816525</td><td>1.40613</td><td>-2.788149</td><td>1.527157</td><td>1.377196</td><td>0.809322</td><td>4</td><td>3</td><td>11</td><td>-1.142846</td><td>0.255657</td><td>-0.589891</td><td>-0.194643</td><td>-1.396933</td><td>-0.544472</td><td>0.455939</td><td>1.345349</td><td>-1.497517</td><td>-0.453106</td><td>-0.511397</td><td>1.153373</td><td>1.024766</td><td>0.727953</td><td>-0.805364</td><td>0.425667</td><td>3.304503</td><td>2.033448</td><td>4.556169</td><td>1.784292</td><td>0.202007</td><td>-0.711492</td><td>0.055067</td><td>-0.587364</td><td>-1.103039</td><td>0.416081</td><td>-0.582688</td><td>-0.205636</td><td>-0.101051</td><td>-0.373885</td><td>0.610414</td><td>0.830006</td><td>-0.512456</td><td>0.776823</td><td>0.907171</td><td>-0.480423</td><td>2</td><td>0.022386</td><td>0.202336</td></tr><tr><td>3</td><td>500</td><td>0</td><td>5</td><td>2.134526</td><td>1.084432</td><td>0.675255</td><td>2.133698</td><td>1.475829</td><td>-3.227231</td><td>2.222543</td><td>1.222155</td><td>1.151731</td><td>2</td><td>10</td><td>171</td><td>-0.712514</td><td>0.196453</td><td>-0.557814</td><td>-0.523046</td><td>0.472192</td><td>-0.368291</td><td>-0.41921</td><td>-0.5144</td><td>0.35587</td><td>-0.584581</td><td>-0.376332</td><td>1.597</td><td>1.244102</td><td>1.757831</td><td>-0.580152</td><td>3.298602</td><td>1.789745</td><td>1.540232</td><td>2.198317</td><td>0.873631</td><td>0.202007</td><td>-0.736673</td><td>-0.125636</td><td>-0.435479</td><td>-1.026445</td><td>0.595562</td><td>-0.275738</td><td>0.304594</td><td>0.026424</td><td>0.218401</td><td>0.22315</td><td>0.718107</td><td>-0.379552</td><td>0.082477</td><td>0.791446</td><td>-0.93745</td><td>2</td><td>2.814211</td><td>2.403637</td></tr><tr><td>4</td><td>500</td><td>0</td><td>7</td><td>1.221901</td><td>1.327554</td><td>0.970756</td><td>1.754374</td><td>1.413643</td><td>-2.826833</td><td>3.255956</td><td>2.215951</td><td>1.221475</td><td>11</td><td>7</td><td>76</td><td>-0.735281</td><td>-0.477965</td><td>-0.704184</td><td>0.054108</td><td>-0.476889</td><td>1.965223</td><td>-1.149339</td><td>-1.140535</td><td>-0.522937</td><td>2.894117</td><td>3.936696</td><td>1.766899</td><td>1.632632</td><td>1.275895</td><td>-0.739147</td><td>-0.227422</td><td>0.390431</td><td>0.709902</td><td>0.411804</td><td>0.148216</td><td>0.202007</td><td>-0.924841</td><td>-0.297648</td><td>-0.718929</td><td>-1.162525</td><td>-0.303834</td><td>-1.090611</td><td>-1.870387</td><td>-1.62065</td><td>-0.753824</td><td>-0.786366</td><td>-0.905661</td><td>0.536415</td><td>0.66507</td><td>0.34449</td><td>1.543351</td><td>2</td><td>3.596194</td><td>2.891145</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"path=r\"D:\\jane-street-real-time-market-data-forecasting\"\nimport os\n\n# Define a specific file name\nfile_name = \"gbm_augmented_training_data_2024-12-131.parquet\"\n\n# Combine the path and file name\nfile_path = os.path.join(path, file_name)\n\n# Save the DataFrame as a Parquet file\ndf.write_parquet(file_path)\n\nprint(f\"DataFrame saved to {file_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:46:36.883215Z","iopub.status.idle":"2024-12-14T18:46:36.883525Z","shell.execute_reply.started":"2024-12-14T18:46:36.883379Z","shell.execute_reply":"2024-12-14T18:46:36.883396Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Code below runs into memory issues ","metadata":{}},{"cell_type":"code","source":"df.shape[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T01:29:16.337026Z","iopub.execute_input":"2024-12-16T01:29:16.337654Z","iopub.status.idle":"2024-12-16T01:29:16.349437Z","shell.execute_reply.started":"2024-12-16T01:29:16.337603Z","shell.execute_reply":"2024-12-16T01:29:16.348076Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"53"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import polars as pl\n\ndef standard_scale_all_columns(lazy_frame: pl.LazyFrame) -> pl.LazyFrame:\n    \"\"\"\n    Apply standard scaling (z-score normalization) to all columns in a LazyFrame.\n    Adds new columns with \"_scaled\" suffix and excludes the original columns.\n\n    :param lazy_frame: Input Polars LazyFrame.\n    :return: LazyFrame with only scaled columns.\n    \"\"\"\n    scaled_columns = []\n\n    # Iterate over all columns\n    for column in lazy_frame.columns:\n        # Calculate mean and standard deviation\n        mean_value = lazy_frame.select(pl.col(column).mean()).collect().item()\n        std_value = lazy_frame.select(pl.col(column).std()).collect().item()\n\n        print(f\"Scaling column: {column} | Mean: {mean_value} | Std: {std_value}\")\n\n        # Avoid scaling columns with zero standard deviation\n        if std_value != 0:\n            scaled_columns.append(\n                ((pl.col(column) - mean_value) / std_value).alias(f\"{column}_scaled\")\n            )\n        else:\n            print(f\"Skipping column: {column} (Zero Std)\")\n\n    # Return the LazyFrame with only the scaled columns\n    return lazy_frame.select(scaled_columns)\n\n# Assuming `lazy_frame` is already defined\nscaled_lazy_frame = standard_scale_all_columns(lazy_frame)\n\n# Collect and inspect the result (use .collect() instead of .fetch())\nscaled_df = scaled_lazy_frame.collect()\n\n# Show the first 20 rows of the result\nscaled_df.head(20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T19:53:51.810018Z","iopub.execute_input":"2025-01-03T19:53:51.810888Z","iopub.status.idle":"2025-01-03T19:54:24.680440Z","shell.execute_reply.started":"2025-01-03T19:53:51.810819Z","shell.execute_reply":"2025-01-03T19:54:24.679585Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3775733350.py:14: PerformanceWarning: Determining the column names of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().names()` to get the column names without this warning.\n  for column in lazy_frame.columns:\n","output_type":"stream"},{"name":"stdout","text":"Scaling column: index | Mean: 19788590.0 | Std: 11424948.196395837\nScaling column: date_id | Mean: 1144.6263971403118 | Std: 333.9367630202352\nScaling column: time_id | Mean: 477.2342533441177 | Std: 276.62488559910355\nScaling column: symbol_id | Mean: 18.78755407061458 | Std: 11.22116296721916\nScaling column: weight | Mean: 2.0404882431030273 | Std: 1.1429258584976196\nScaling column: feature_00 | Mean: 0.5996853709220886 | Std: 1.3447489738464355\nScaling column: feature_01 | Mean: 0.010678956285119057 | Std: 1.100235104560852\nScaling column: feature_02 | Mean: 0.5985499024391174 | Std: 1.33966863155365\nScaling column: feature_03 | Mean: 0.5982627868652344 | Std: 1.3397148847579956\nScaling column: feature_04 | Mean: 0.0006053933757357299 | Std: 1.04727303981781\nScaling column: feature_05 | Mean: -0.0492791123688221 | Std: 1.017353892326355\nScaling column: feature_06 | Mean: -0.0062563312239944935 | Std: 1.0708004236221313\nScaling column: feature_07 | Mean: -0.017733534798026085 | Std: 1.0592600107192993\nScaling column: feature_09 | Mean: 32.847024198110525 | Std: 23.596384202715434\nScaling column: feature_10 | Mean: 4.945420670562666 | Std: 3.1364869216548237\nScaling column: feature_11 | Mean: 169.49973566838932 | Std: 161.5706947970349\nScaling column: feature_12 | Mean: -0.04611845314502716 | Std: 0.9222444891929626\nScaling column: feature_13 | Mean: -0.03457321971654892 | Std: 0.8766943216323853\nScaling column: feature_14 | Mean: -0.05305733159184456 | Std: 0.9168614745140076\nScaling column: feature_20 | Mean: -0.3037659227848053 | Std: 0.8656187057495117\nScaling column: feature_22 | Mean: 0.07786177843809128 | Std: 0.9736226201057434\nScaling column: feature_23 | Mean: 0.06596975773572922 | Std: 0.9301428198814392\nScaling column: feature_24 | Mean: 0.7244414687156677 | Std: 1.4733128547668457\nScaling column: feature_25 | Mean: 0.09192584455013275 | Std: 1.0167282819747925\nScaling column: feature_28 | Mean: -0.17744912207126617 | Std: 1.0369120836257935\nScaling column: feature_29 | Mean: -0.24660009145736694 | Std: 0.8927310109138489\nScaling column: feature_30 | Mean: -0.31429895758628845 | Std: 0.9240338802337646\nScaling column: feature_34 | Mean: 0.5073190927505493 | Std: 1.3418055772781372\nScaling column: feature_35 | Mean: 0.5050215125083923 | Std: 1.3370954990386963\nScaling column: feature_36 | Mean: 0.0019609055016189814 | Std: 0.8890126943588257\nScaling column: feature_38 | Mean: 0.06123571842908859 | Std: 0.9092225432395935\nScaling column: feature_47 | Mean: -0.013151652179658413 | Std: 1.1526169776916504\nScaling column: feature_48 | Mean: -0.0022844939958304167 | Std: 0.7431825995445251\nScaling column: feature_49 | Mean: -0.005490540061146021 | Std: 0.7863720655441284\nScaling column: feature_59 | Mean: -0.0033552157692611217 | Std: 0.9331784248352051\nScaling column: feature_60 | Mean: -0.00902535580098629 | Std: 0.9385390281677246\nScaling column: feature_61 | Mean: 0.01859021745622158 | Std: 1.1210099458694458\nScaling column: feature_67 | Mean: -0.05007663741707802 | Std: 0.9055933952331543\nScaling column: feature_68 | Mean: -0.030708175152540207 | Std: 0.8557104468345642\nScaling column: feature_69 | Mean: -0.05143805965781212 | Std: 0.8946112394332886\nScaling column: feature_70 | Mean: -0.039385586977005005 | Std: 0.9294185042381287\nScaling column: feature_71 | Mean: -0.0278495941311121 | Std: 0.8421511650085449\nScaling column: feature_72 | Mean: -0.04796427860856056 | Std: 0.9106836318969727\nScaling column: responder_0 | Mean: -0.0027314533945173025 | Std: 0.52800452709198\nScaling column: responder_1 | Mean: -0.0029462750535458326 | Std: 0.4963032305240631\nScaling column: responder_2 | Mean: -0.00040791594074107707 | Std: 0.5426373481750488\nScaling column: responder_3 | Mean: -0.0191570483148098 | Std: 0.7828688621520996\nScaling column: responder_4 | Mean: -0.014398724772036076 | Std: 0.8302150964736938\nScaling column: responder_5 | Mean: -0.019321076571941376 | Std: 0.6965336203575134\nScaling column: responder_7 | Mean: 0.004134914837777615 | Std: 0.9111637473106384\nScaling column: responder_8 | Mean: -0.0007717414409853518 | Std: 0.8569941520690918\nScaling column: partition_id | Mean: 6.228772938628449 | Std: 1.951017491810667\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"shape: (20, 52)\n┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n│ index_sca ┆ date_id_s ┆ time_id_s ┆ symbol_id ┆ … ┆ responder ┆ responder ┆ responder ┆ partitio │\n│ led       ┆ caled     ┆ caled     ┆ _scaled   ┆   ┆ _5_scaled ┆ _7_scaled ┆ _8_scaled ┆ n_id_sca │\n│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ led      │\n│ f64       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f32       ┆ f32       ┆ f32       ┆ ---      │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ f64      │\n╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n│ -1.732051 ┆ -1.930385 ┆ -1.725204 ┆ -1.585179 ┆ … ┆ -0.357371 ┆ -0.008936 ┆ 0.334888  ┆ -2.16747 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n│ -1.732051 ┆ -1.930385 ┆ -1.725204 ┆ -1.496062 ┆ … ┆ 0.561255  ┆ 0.899146  ┆ 0.495921  ┆ -2.16747 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n│ -1.732051 ┆ -1.930385 ┆ -1.725204 ┆ -1.406945 ┆ … ┆ -0.707985 ┆ 0.99108   ┆ -0.559691 ┆ -2.16747 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n│ -1.73205  ┆ -1.930385 ┆ -1.725204 ┆ -1.22871  ┆ … ┆ -0.517177 ┆ 0.864073  ┆ -1.09298  ┆ -2.16747 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n│ -1.73205  ┆ -1.930385 ┆ -1.725204 ┆ -1.050475 ┆ … ┆ 0.79786   ┆ 0.373539  ┆ 1.801789  ┆ -2.16747 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n│ -1.732049 ┆ -1.930385 ┆ -1.725204 ┆ 0.018933  ┆ … ┆ -1.676524 ┆ 0.511835  ┆ -2.07771  ┆ -2.16747 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n│ -1.732049 ┆ -1.930385 ┆ -1.725204 ┆ 0.10805   ┆ … ┆ 0.617806  ┆ -0.595425 ┆ 5.835246  ┆ -2.16747 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n│ -1.732049 ┆ -1.930385 ┆ -1.725204 ┆ 0.197167  ┆ … ┆ 0.352572  ┆ -0.019968 ┆ 0.919907  ┆ -2.16747 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n│ -1.732049 ┆ -1.930385 ┆ -1.725204 ┆ 0.286285  ┆ … ┆ -2.709617 ┆ 0.012703  ┆ -3.583113 ┆ -2.16747 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n│ -1.732049 ┆ -1.930385 ┆ -1.725204 ┆ 0.375402  ┆ … ┆ 3.577767  ┆ 1.265357  ┆ 5.835246  ┆ -2.16747 │\n│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (20, 52)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index_scaled</th><th>date_id_scaled</th><th>time_id_scaled</th><th>symbol_id_scaled</th><th>weight_scaled</th><th>feature_00_scaled</th><th>feature_01_scaled</th><th>feature_02_scaled</th><th>feature_03_scaled</th><th>feature_04_scaled</th><th>feature_05_scaled</th><th>feature_06_scaled</th><th>feature_07_scaled</th><th>feature_09_scaled</th><th>feature_10_scaled</th><th>feature_11_scaled</th><th>feature_12_scaled</th><th>feature_13_scaled</th><th>feature_14_scaled</th><th>feature_20_scaled</th><th>feature_22_scaled</th><th>feature_23_scaled</th><th>feature_24_scaled</th><th>feature_25_scaled</th><th>feature_28_scaled</th><th>feature_29_scaled</th><th>feature_30_scaled</th><th>feature_34_scaled</th><th>feature_35_scaled</th><th>feature_36_scaled</th><th>feature_38_scaled</th><th>feature_47_scaled</th><th>feature_48_scaled</th><th>feature_49_scaled</th><th>feature_59_scaled</th><th>feature_60_scaled</th><th>feature_61_scaled</th><th>feature_67_scaled</th><th>feature_68_scaled</th><th>feature_69_scaled</th><th>feature_70_scaled</th><th>feature_71_scaled</th><th>feature_72_scaled</th><th>responder_0_scaled</th><th>responder_1_scaled</th><th>responder_2_scaled</th><th>responder_3_scaled</th><th>responder_4_scaled</th><th>responder_5_scaled</th><th>responder_7_scaled</th><th>responder_8_scaled</th><th>partition_id_scaled</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f64</td></tr></thead><tbody><tr><td>-1.732051</td><td>-1.930385</td><td>-1.725204</td><td>-1.585179</td><td>2.040477</td><td>0.270232</td><td>0.759384</td><td>1.000758</td><td>0.422834</td><td>-3.061025</td><td>1.424884</td><td>1.778826</td><td>0.716935</td><td>-0.925863</td><td>0.655058</td><td>-0.578692</td><td>-0.892256</td><td>0.524887</td><td>-0.561121</td><td>1.558612</td><td>2.697594</td><td>1.763503</td><td>-0.384152</td><td>0.562494</td><td>1.918553</td><td>-0.107039</td><td>-0.152219</td><td>0.768949</td><td>0.782158</td><td>2.835411</td><td>-1.124171</td><td>1.078947</td><td>2.003188</td><td>1.738758</td><td>1.794467</td><td>0.692162</td><td>0.163617</td><td>-0.872096</td><td>0.431578</td><td>-0.417251</td><td>-1.037347</td><td>0.737919</td><td>-0.440477</td><td>-1.488799</td><td>-0.976204</td><td>-1.776727</td><td>-0.775518</td><td>-0.386163</td><td>-0.357371</td><td>-0.008936</td><td>0.334888</td><td>-2.167471</td></tr><tr><td>-1.732051</td><td>-1.930385</td><td>-1.725204</td><td>-1.496062</td><td>-0.735881</td><td>0.297153</td><td>0.684958</td><td>0.669876</td><td>0.316494</td><td>-3.333689</td><td>2.483542</td><td>1.543384</td><td>0.72546</td><td>2.040693</td><td>-0.939083</td><td>-0.68391</td><td>-1.239589</td><td>-0.381948</td><td>-0.476866</td><td>-0.317605</td><td>-0.559189</td><td>-0.965963</td><td>-0.344946</td><td>-0.265988</td><td>0.674835</td><td>-0.102063</td><td>-0.482289</td><td>0.449302</td><td>-0.422915</td><td>-1.794485</td><td>-0.460911</td><td>-0.405879</td><td>-1.937045</td><td>-1.006962</td><td>-1.006904</td><td>-0.541932</td><td>0.163617</td><td>-1.106403</td><td>-0.395187</td><td>-0.713123</td><td>-0.673451</td><td>-0.243691</td><td>-0.775164</td><td>-0.547582</td><td>-0.657878</td><td>0.321445</td><td>0.181542</td><td>0.744561</td><td>0.561255</td><td>0.899146</td><td>0.495921</td><td>-2.167471</td></tr><tr><td>-1.732051</td><td>-1.930385</td><td>-1.725204</td><td>-1.406945</td><td>-1.182244</td><td>1.15772</td><td>0.335378</td><td>0.909162</td><td>0.603014</td><td>-2.662872</td><td>1.549545</td><td>1.29198</td><td>0.780786</td><td>-1.222519</td><td>-0.620255</td><td>-0.980993</td><td>-1.189194</td><td>0.33105</td><td>-0.585512</td><td>0.126064</td><td>-1.51475</td><td>-0.656288</td><td>-0.182244</td><td>1.232801</td><td>-1.273076</td><td>-0.231319</td><td>-0.213301</td><td>0.481481</td><td>0.388712</td><td>0.816627</td><td>-0.953121</td><td>0.380715</td><td>4.449496</td><td>2.592842</td><td>4.886014</td><td>1.910754</td><td>0.163617</td><td>-0.730367</td><td>0.100239</td><td>-0.59906</td><td>-1.144429</td><td>0.527139</td><td>-0.587167</td><td>-0.384285</td><td>-0.197671</td><td>-0.688262</td><td>0.804185</td><td>1.017092</td><td>-0.707985</td><td>0.99108</td><td>-0.559691</td><td>-2.167471</td></tr><tr><td>-1.73205</td><td>-1.930385</td><td>-1.725204</td><td>-1.22871</td><td>0.082279</td><td>0.360473</td><td>0.604031</td><td>1.145917</td><td>0.655039</td><td>-3.082134</td><td>2.23307</td><td>1.14719</td><td>1.10404</td><td>-1.307278</td><td>1.611542</td><td>0.009285</td><td>-0.72258</td><td>0.26352</td><td>-0.550527</td><td>-0.253322</td><td>0.405013</td><td>-0.466875</td><td>-0.776245</td><td>-0.59635</td><td>0.514333</td><td>-0.378592</td><td>-0.067133</td><td>0.812101</td><td>0.55275</td><td>1.975078</td><td>-0.705424</td><td>2.873247</td><td>2.411292</td><td>1.965637</td><td>2.359326</td><td>0.940458</td><td>0.163617</td><td>-0.758173</td><td>-0.110934</td><td>-0.429283</td><td>-1.062018</td><td>0.740261</td><td>-0.250113</td><td>0.582052</td><td>0.059177</td><td>0.403233</td><td>0.309512</td><td>0.882309</td><td>-0.517177</td><td>0.864073</td><td>-1.09298</td><td>-2.167471</td></tr><tr><td>-1.73205</td><td>-1.930385</td><td>-1.725204</td><td>-1.050475</td><td>-0.716221</td><td>0.541267</td><td>0.872611</td><td>0.862769</td><td>0.608622</td><td>-2.69981</td><td>3.248855</td><td>2.075277</td><td>1.169882</td><td>-0.925863</td><td>0.655058</td><td>-0.578692</td><td>-0.747267</td><td>-0.505754</td><td>-0.710169</td><td>0.413432</td><td>-0.56978</td><td>2.041894</td><td>-1.271815</td><td>-1.212183</td><td>-0.333189</td><td>3.518101</td><td>4.600475</td><td>0.93872</td><td>0.843329</td><td>1.432977</td><td>-0.880294</td><td>-0.185899</td><td>0.528425</td><td>0.909738</td><td>0.444887</td><td>0.167539</td><td>0.163617</td><td>-0.965957</td><td>-0.311952</td><td>-0.746125</td><td>-1.208433</td><td>-0.327713</td><td>-1.144906</td><td>-3.537196</td><td>-3.259507</td><td>-1.388433</td><td>-0.979996</td><td>-1.073532</td><td>0.79786</td><td>0.373539</td><td>1.801789</td><td>-2.167471</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>-1.732049</td><td>-1.930385</td><td>-1.725204</td><td>0.018933</td><td>1.219948</td><td>0.515679</td><td>0.776773</td><td>0.470273</td><td>0.58959</td><td>-2.860221</td><td>1.247012</td><td>1.470888</td><td>0.75299</td><td>-1.222519</td><td>-0.620255</td><td>-0.980993</td><td>-1.240463</td><td>1.119004</td><td>-0.241099</td><td>0.879167</td><td>1.157937</td><td>0.064957</td><td>-0.097379</td><td>1.934862</td><td>0.195268</td><td>-0.44387</td><td>-0.297931</td><td>0.379049</td><td>0.584367</td><td>-0.397848</td><td>-0.757852</td><td>1.388213</td><td>0.62859</td><td>0.379404</td><td>1.010202</td><td>0.562223</td><td>0.163617</td><td>-0.692915</td><td>2.174026</td><td>-0.223337</td><td>-0.78744</td><td>0.990932</td><td>-0.237429</td><td>-0.177659</td><td>-0.083648</td><td>-0.080935</td><td>0.130522</td><td>0.728066</td><td>-1.676524</td><td>0.511835</td><td>-2.07771</td><td>-2.167471</td></tr><tr><td>-1.732049</td><td>-1.930385</td><td>-1.725204</td><td>0.10805</td><td>-1.016455</td><td>0.629288</td><td>0.455708</td><td>0.950351</td><td>0.653744</td><td>-3.67646</td><td>2.292024</td><td>1.001169</td><td>0.767875</td><td>0.387897</td><td>0.017401</td><td>-0.120689</td><td>-0.890836</td><td>-0.255541</td><td>-0.814234</td><td>-0.596444</td><td>-1.320486</td><td>-1.4123</td><td>0.053483</td><td>1.43003</td><td>-1.537355</td><td>-0.162973</td><td>-0.239108</td><td>1.996285</td><td>2.298188</td><td>-3.532068</td><td>-0.356178</td><td>5.011493</td><td>36.302876</td><td>8.413575</td><td>6.599238</td><td>3.883462</td><td>0.163617</td><td>-1.104139</td><td>-0.303107</td><td>-0.48144</td><td>-0.923262</td><td>-0.015714</td><td>-0.618508</td><td>-8.401939</td><td>-3.782612</td><td>-9.213506</td><td>-3.437134</td><td>-1.300797</td><td>0.617806</td><td>-0.595425</td><td>5.835246</td><td>-2.167471</td></tr><tr><td>-1.732049</td><td>-1.930385</td><td>-1.725204</td><td>0.197167</td><td>-1.413294</td><td>0.296001</td><td>1.008594</td><td>1.373909</td><td>0.636961</td><td>-3.006007</td><td>2.293941</td><td>1.053478</td><td>0.952408</td><td>0.048862</td><td>-0.301427</td><td>0.275423</td><td>-0.749665</td><td>-0.172607</td><td>-0.990205</td><td>-2.039168</td><td>-1.389319</td><td>-1.34404</td><td>-0.359302</td><td>-0.231051</td><td>-1.279083</td><td>0.041034</td><td>0.009189</td><td>0.689949</td><td>0.638129</td><td>3.03904</td><td>-1.397423</td><td>1.733307</td><td>6.918233</td><td>3.130863</td><td>5.631354</td><td>2.558505</td><td>0.163617</td><td>-1.188982</td><td>-0.410177</td><td>-0.833114</td><td>-1.131549</td><td>0.198834</td><td>-0.514431</td><td>-1.422861</td><td>-0.890403</td><td>-0.759262</td><td>-1.317922</td><td>-0.215864</td><td>0.352572</td><td>-0.019968</td><td>0.919907</td><td>-2.167471</td></tr><tr><td>-1.732049</td><td>-1.930385</td><td>-1.725204</td><td>0.286285</td><td>-0.898856</td><td>0.65588</td><td>0.722651</td><td>0.867834</td><td>1.066505</td><td>-2.975635</td><td>1.305695</td><td>1.153996</td><td>0.892531</td><td>-0.120655</td><td>1.611542</td><td>-0.968615</td><td>-0.799615</td><td>-0.38141</td><td>-0.792647</td><td>-0.178708</td><td>-1.254065</td><td>-1.409832</td><td>0.221684</td><td>2.027138</td><td>-1.132544</td><td>-0.391288</td><td>-0.306427</td><td>0.367415</td><td>0.080296</td><td>2.542217</td><td>-0.731548</td><td>-0.824509</td><td>-3.092822</td><td>0.468156</td><td>1.612046</td><td>1.050152</td><td>0.163617</td><td>-0.836679</td><td>-0.425557</td><td>-0.68553</td><td>-1.031054</td><td>-0.435328</td><td>-0.82441</td><td>-1.182653</td><td>-0.239661</td><td>1.529177</td><td>0.366462</td><td>-0.045109</td><td>-2.709617</td><td>0.012703</td><td>-3.583113</td><td>-2.167471</td></tr><tr><td>-1.732049</td><td>-1.930385</td><td>-1.725204</td><td>0.375402</td><td>-0.790544</td><td>0.672231</td><td>0.367888</td><td>0.756864</td><td>0.572921</td><td>-2.964023</td><td>3.169065</td><td>2.108664</td><td>0.914525</td><td>0.048862</td><td>-0.301427</td><td>0.275423</td><td>-1.09404</td><td>-0.496274</td><td>-0.636148</td><td>-2.392683</td><td>-0.949237</td><td>-1.27792</td><td>-1.129922</td><td>-1.188533</td><td>0.437374</td><td>-0.849673</td><td>-0.143822</td><td>0.48392</td><td>0.487112</td><td>0.483755</td><td>-0.606985</td><td>0.560539</td><td>5.929777</td><td>2.426361</td><td>-1.22925</td><td>-0.158203</td><td>0.163617</td><td>-1.134663</td><td>-0.463589</td><td>-0.506834</td><td>-1.102808</td><td>-0.46153</td><td>-0.913741</td><td>3.645809</td><td>-0.047438</td><td>-0.623287</td><td>3.870949</td><td>2.497108</td><td>3.577767</td><td>1.265357</td><td>5.835246</td><td>-2.167471</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def reduce_mem_usage_pl(df, float16_as32=True):\n    # Calculate initial memory usage in MB\n    start_mem = df.estimated_size() / 1024**2\n    print(f'Memory usage of dataframe is {start_mem:.2f} MB')\n    \n    for col in df.columns:\n        col_type = df.schema[col]\n        \n        if col_type == pl.Int64 or col_type == pl.Float64:  # Process only numeric columns\n            c_min, c_max = df.select(\n                pl.col(col).min().alias(f\"{col}_min\"),\n                pl.col(col).max().alias(f\"{col}_max\")\n            ).row(0)\n            \n            # Handle integer types\n            if col_type == pl.Int64:\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df = df.with_columns(pl.col(col).cast(pl.Int8))\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df = df.with_columns(pl.col(col).cast(pl.Int16))\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df = df.with_columns(pl.col(col).cast(pl.Int32))\n            \n            # Handle floating point types\n            elif col_type == pl.Float64:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    if float16_as32:\n                        df = df.with_columns(pl.col(col).cast(pl.Float32))\n                    else:\n                        df = df.with_columns(pl.col(col).cast(pl.Float16))\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df = df.with_columns(pl.col(col).cast(pl.Float32))\n\n    # Calculate final memory usage in MB\n    end_mem = df.estimated_size() / 1024**2\n    print(f'Memory usage after optimization is: {end_mem:.2f} MB')\n    print(f'Decreased by {(100 * (start_mem - end_mem) / start_mem):.1f}%')\n    \n    return df#memory_usage() is the memory usage of each column of df, sum is the sum of them, B->KB->MB\n    \n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype#type of column name\n        if col_type != object and str(col_type)!='category':#Is not an object, which means that variables of numeric type are processed here\n            c_min,c_max = df[col].min(),df[col].max()#Find the maximum and minimum values of this column\n            if str(col_type)[:3] =='int':#If it is a variable of type int, whether it is int8, int16, int32 or int64\n                #If the value range of this column is within the value range of int8, then convert the type (-128 to 127)\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                #If the value range of this column is within the value range of int16, then convert the type (-32,768 to 32,767)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                #If the value range of this column is within the value range of int32, then convert the type (-2,147,483,648 to 2,147,483,647)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                #If the value range of this column is within the value range of int64, then convert the type (-9,223,372,036,854,775,808 to 9,223,372,036,854,775,807)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:#If it is a floating-point number type.\n                #If the value is within the range of float16, if you feel that you need higher precision, you can consider float32\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    if float16_as32:#If the data needs higher accuracy, you can choose float32\n                        df[col] = df[col].astype(np.float32)\n                    else:\n                        df[col] = df[col].astype(np.float16)  \n                #If the value is within the range of float32, type it\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                #If the value is within the range of float64, type it\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.estimated_size() / 1024**2\n    print(f'Memory usage after optimization is: {end_mem:.2f} MB')\n    print(f'Decreased by {(100 * (start_mem - end_mem) / start_mem):.1f}%')\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T19:54:24.682259Z","iopub.execute_input":"2025-01-03T19:54:24.682518Z","iopub.status.idle":"2025-01-03T19:54:24.696684Z","shell.execute_reply.started":"2025-01-03T19:54:24.682493Z","shell.execute_reply":"2025-01-03T19:54:24.695874Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport gc\ndel lazy_frame\ngc.collect() \nscaled_df=reduce_mem_usage_pl(scaled_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T19:54:24.697732Z","iopub.execute_input":"2025-01-03T19:54:24.697997Z","iopub.status.idle":"2025-01-03T19:54:25.816303Z","shell.execute_reply.started":"2025-01-03T19:54:24.697971Z","shell.execute_reply":"2025-01-03T19:54:25.815357Z"}},"outputs":[{"name":"stdout","text":"Memory usage of dataframe is 9058.50 MB\nMemory usage after optimization is: 7850.70 MB\nDecreased by 13.3%\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"Below code is setting up data as a tensor then passing to data loader which feeds the data to the model for training","metadata":{}},{"cell_type":"markdown","source":"When running the code below converting to tensors might be to much at once causing ram issues so should be done at diff intervals or a better option is just reading in the tensors from some files,everthing should be max 20g and 30 is avaible so should be no issue worried about training model however","metadata":{}},{"cell_type":"code","source":"import torch\nimport polars as pl\nimport time\nfrom sklearn.preprocessing import StandardScaler\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch import nn\nimport torch.optim as optim\n\n#x_train = scaled_df.drop(['responder_6']) already done above\n#y = df['responder_6'] should already be done above\n\ny_tensor = torch.tensor(y.to_numpy(), dtype=torch.float32).view(-1, 1)  # Convert Polars Series to NumPy array\ndel y\ntime.sleep(10)\nX_tensor = torch.tensor(scaled_df.to_numpy(), dtype=torch.float32)\n#weights_tensor = torch.tensor(weights.to_numpy(), dtype=torch.float32).view(-1, 1)  # Convert weights to tensor\ndel scaled_df\ntime.sleep(10)\nweights=weights.collect()\nweights=torch.tensor(weights.to_numpy(), dtype=torch.float32).view(-1, 1)\n\n\n# Assuming your data, targets, and weights are already loaded as tensors\ndataset = TensorDataset(X_tensor, y_tensor, weights)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T19:54:29.089661Z","iopub.execute_input":"2025-01-03T19:54:29.090004Z","iopub.status.idle":"2025-01-03T19:55:00.834423Z","shell.execute_reply.started":"2025-01-03T19:54:29.089973Z","shell.execute_reply":"2025-01-03T19:55:00.833562Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_loader = DataLoader(dataset, batch_size=512, shuffle=True, num_workers=4, pin_memory=True)\nprint(\"done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T19:55:00.836489Z","iopub.execute_input":"2025-01-03T19:55:00.836874Z","iopub.status.idle":"2025-01-03T19:55:00.841490Z","shell.execute_reply.started":"2025-01-03T19:55:00.836822Z","shell.execute_reply":"2025-01-03T19:55:00.840699Z"}},"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import torch\nfrom torch.utils.tensorboard import SummaryWriter\nimport time\nimport psutil  # For monitoring system resources\nimport torch.cuda\nwriter = SummaryWriter(log_dir='runs/experiment_name')\n\n# Define a helper function to get GPU memory usage\ndef get_gpu_usage():\n    if torch.cuda.is_available():\n        gpu_memory = torch.cuda.memory_allocated() / (1024 ** 3)  # In GB\n        gpu_memory_max = torch.cuda.memory_reserved() / (1024 ** 3)  # Max GPU Memory in GB\n        return gpu_memory, gpu_memory_max\n    return 0, 0\n\n# Define a helper function to estimate time remaining based on elapsed time\ndef get_time_left(start_time, epoch, total_epochs):\n    elapsed_time = time.time() - start_time\n    time_per_epoch = elapsed_time / (epoch + 1)\n    time_left = time_per_epoch * (total_epochs - epoch - 1)\n    return time_left\nprint(\"done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T19:55:20.440381Z","iopub.execute_input":"2025-01-03T19:55:20.441053Z","iopub.status.idle":"2025-01-03T19:55:33.751914Z","shell.execute_reply.started":"2025-01-03T19:55:20.441021Z","shell.execute_reply":"2025-01-03T19:55:33.750912Z"}},"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"\n\nclass WeightedR2Score(tf.keras.metrics.Metric):\n    def __init__(self, name='weighted_r2', **kwargs):\n        super(WeightedR2Score, self).__init__(name=name, **kwargs)\n        self.sum_squared_error = self.add_weight(name='sum_squared_error', initializer='zeros')\n        self.sum_squared_total = self.add_weight(name='sum_squared_total', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        if sample_weight is not None:\n            sample_weight = tf.cast(sample_weight, dtype=tf.float32)\n        else:\n            sample_weight = tf.ones_like(y_true, dtype=tf.float32)\n\n        # Weighted squared error\n        weighted_squared_error = sample_weight * tf.square(y_true - y_pred)\n\n        # Weighted total squared error\n        weighted_squared_total = sample_weight * tf.square(y_true - tf.reduce_mean(y_true))\n\n        self.sum_squared_error.assign_add(tf.reduce_sum(weighted_squared_error))\n        self.sum_squared_total.assign_add(tf.reduce_sum(weighted_squared_total))\n\n    def result(self):\n        # Calculate the weighted R2 score\n        return 1 - (self.sum_squared_error / (self.sum_squared_total + tf.keras.backend.epsilon()))\n\n    def reset_states(self):\n        # Reset metrics for each epoch\n        self.sum_squared_error.assign(0)\n        self.sum_squared_total.assign(0)\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='mean_squared_error',\n              metrics=[WeightedR2Score()])\n\n# Print model summary to verify parameter count\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T19:08:42.238006Z","iopub.execute_input":"2024-12-21T19:08:42.239051Z","iopub.status.idle":"2024-12-21T19:08:42.297114Z","shell.execute_reply.started":"2024-12-21T19:08:42.239010Z","shell.execute_reply":"2024-12-21T19:08:42.296219Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m13,568\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,568</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,785\u001b[0m (214.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,785</span> (214.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m54,785\u001b[0m (214.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,785</span> (214.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T21:01:55.700546Z","iopub.execute_input":"2024-11-15T21:01:55.700946Z","iopub.status.idle":"2024-11-15T21:01:55.721687Z","shell.execute_reply.started":"2024-11-15T21:01:55.700911Z","shell.execute_reply":"2024-11-15T21:01:55.720508Z"}},"outputs":[],"execution_count":30}]}